{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mnist Classifier using RNN LSTM Cells\n",
    "Source: https://www.tensorflow.org/guide/keras/rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"rnn_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "rnn_1 (RNN)                  (None, 64)                23808     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 24,714\n",
      "Trainable params: 24,586\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "batchSize = 64\n",
    "inputDim = 28\n",
    "units = 64\n",
    "outputSize = 10\n",
    "\n",
    "lstmLayer = layers.RNN(layers.LSTMCell(units), input_shape=(None, inputDim))\n",
    "# lstmLayer = layers.LSTM(units, input_shape=(None, inputDim))\n",
    "\n",
    "model = tf.keras.Sequential(name='rnn_model')\n",
    "model.add(lstmLayer)\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dense(outputSize, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 15s 243us/sample - loss: 0.9446 - accuracy: 0.6990 - val_loss: 0.5266 - val_accuracy: 0.8317\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 16s 259us/sample - loss: 0.3964 - accuracy: 0.8822 - val_loss: 0.2755 - val_accuracy: 0.9139\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 16s 271us/sample - loss: 0.2540 - accuracy: 0.9234 - val_loss: 0.2612 - val_accuracy: 0.9174\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 13s 218us/sample - loss: 0.1986 - accuracy: 0.9395 - val_loss: 0.3199 - val_accuracy: 0.8899\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 13s 210us/sample - loss: 0.1667 - accuracy: 0.9495 - val_loss: 0.2168 - val_accuracy: 0.9286\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f20c35547f0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "             optimizer='sgd',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train,y_train, validation_data=(x_test, y_test),\n",
    "         batch_size=batchSize, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted result is: [9], target result is: 9\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample, sample_label = x_train[4], y_train[4]\n",
    "result = tf.argmax(model.predict_on_batch(tf.expand_dims(sample, 0)), axis=1)\n",
    "\n",
    "plt.imshow(sample, cmap=plt.get_cmap('gray'))\n",
    "plt.axis(\"off\")\n",
    "\n",
    "print('Predicted result is: %s, target result is: %s' % (result.numpy(), sample_label))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
